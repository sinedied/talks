<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>How to become an IA-enhanced developer</title>
  <link rel="stylesheet" href="style.css">
  <script src="remark.min.js"></script>
  <script src="rough-notation.js"></script>
  <script>
    function create() {
      var slideshow = remark.create({
        source: "exclude: true\n<!--\nLe développement augmenté à l'IA: tout ce qui va changer\n\nLes IA chez les devs, c'est comme le sexe chez les ados: tout le monde en parle, mais très peu ont finalement une réelle expérience du sujet. Dans ce talk, nous partagerons notre expérience du développement assisté à l'IA que nous pratiquons depuis les premières versions beta de ces modèles: ce que nous en avons appris, les trucs et astuces, leur limites... Mais ce sera aussi l'occasion de debunker certaines contre-vérités que l'on peut entendre à gauche et à droite.\n\nEn poussant un peu plus, on découvrira également que les bénéfices dépassent le simple fait de générer du code. Ces IA peuvent servir d'outil de feedback, améliorer la qualité, la sécurité et l'accessibilité de nos projets, automatiser des tâches et pourraient même changer complètement l'expérience du recrutement. Qu'on l'accepte ou non, l'IA a *déjà* commencé à changer notre métier.\n\nEntrez dans le quotidien d'un dev du futur, et découvrez ce qui ce cache réellement derrière les sirènes du marketing et des histoires miraculeuses entendues au café!\n\nIntro: https://www.lebigdata.fr/ia-creer-logiciel\nhttps://github.com/danielgross/localpilot\n-->\n---\n\ntitle: How to become an IA-enhanced developer\nclass: animation-fade\nlayout: true\n\n.twitter-handle[\n  @sinedied | @cmaneu\n]\n\n---\n\nclass: hide-handle, full, more-shadow\nbackground-image: url(images/ai-enhanced-developer.jpg)\n\n.title-new.w-55.center[\n# .baseline.bit-larger[IA-enhanced development]\n## .small[What's going to .grad-text[change]]\n]\n\n.full-layer.who.text-right.small.middle.light-text.darkened[\n  .ms.responsive[![](images/ms-full-logo.svg)]\n  |\n  Yohan Lasorsa\n  |\n  Christopher Maneu\n]\n\n.full-layer.space-left.left.full-bottom.no-margin.conf-logo[\n.w-15.responsive.logo-filter[![](images/devoxxma.png)]\n]\n\n<style>\n.conf-logo { padding-bottom: .25em; }\n</style>\n\n???\n\n---\n\nclass: center, middle, hide-handle\n# Who are we?\n\n.table.row.middle.center[\n.col-2[]\n.col-4.center[\n  .w-70.responsive.avatar.bounceInLeft.animated[![](images/me.jpg)]\n\n  **Yohan Lasorsa**<br>\n  .fab.fa-linkedin[] .e[/yohanlasorsa]<br>\n  .fab.fa-x-twitter[] .e[@sinedied]\n]\n.col-4.center[\n  .w-70.responsive.avatar.bounceInUp.animated[![](images/chris.jpg)]\n\n  **Christopher Maneu**<br>\n  .fab.fa-linkedin[] .e[/cmaneu]<br>\n  .fab.fa-x-twitter[] .e[@cmaneu]\n]\n]\n\n---\n\nclass: impact\n# 92% of U.S.-based developers are already using AI coding tools\n\n???\n- Etude faite en juin 23 auprès de 500 devs de sociétés de +1000p\n- Qui utilise ici des outils d'IA pour coder?\n- Qui déjà utilisé ChatGPT pour son boulot?\n  * Pique de démarrage: risques (ex Samsung leak)\n  https://techcrunch.com/2023/05/02/samsung-bans-use-of-generative-ai-tools-like-chatgpt-after-april-internal-data-leak/\n---\n\nclass: center, cover, hide-handle\nbackground-image: url(./images/ai-landscape.jpg)\n\n.full-layer.full-top.blur.with-padding[\n# What are we talking about?\n]\n\n.full-layer.full-bottom.blur.small[\nExtract from **The 2023 MAD (ML/AI/Data) Landscape**\nby Matt Turck - https://mad.firstmark.com/\n]\n]\n\n.here[ ]\n\n<style>\n.here {\n  position: absolute;\n  top: 150px;\n  bottom: 340px;\n  left: 370px;\n  right: 570px;\n}\n</style>\n<script>\nrough('.here', { type: 'circle', color: '#f22', strokeWidth: 4, padding: 50, animationDuration: 2000 }, 1000);\n<\/script>\n\n???\n- Tout le monde fait de l'IA ces temps-ci, de quoi on parles exactement?\n- Focus sur les IA dédiées au développement\n- En particulier sur l'assistance au code\n\n---\n\nclass: center, middle\n# \"AI will replace developers\"\n\n.w-70.responsive[![](./images/will-ai-replace-devs.png)]\n\n.scream.left[.ib.animated.heartBeat.w-20.responsive[![](./images/scream.jpg)]]\n\n<style>\n.scream {\n  position: absolute;\n  bottom: -160px;\n  left: -40px;\n  transform: rotate(20deg);\n}\n</style>\n\n???\n* \"Au secours on va tous perdre notre job\"\n* Est-ce qu'on est les prochains allumeurs de réverbères?\n* Guy de Maupassant: On n'a vraiment peur que de ce qu'on ne comprend pas\n\n---\n\nclass: cover, hide-handle\nbackground-image: url(./images/dual.jpg)\n\n???\n* Believer vs Skeptics: ca marche au top/pas du tout, pourquoi une telle différence d'expérience?\n    - facon de coder, xp level vs esprit critique, techno/langage utilisés, contexte...\n* Objectif: démystifier, comprendre comment ca marche et surtout les limites, pour savoir comment l'utiliser au mieux!\n\n---\n\n.col-6.float-left[\n  .w-80.responsive[![](./images/dummies.jpg)]\n]\n.col-6.float-left[\n  <br><br>\n\n  # LLM crash course\n  - Training\n  - Model types\n  - Tokens\n  - Limits\n  - Embeddings\n  - Prompt engineering\n  - Agents\n]\n\n---\n\nclass: center\n\n# Training\n\n.w-80.responsive[\n  <object data=\"images/llm-training.svg\"></object>\n]\n\n???\n- pre-training: expensive $$$\n- fine-tuning: cheap $\n- RLHF: long and complicated\n\n---\n\nclass: \n\n# Model types\n\n#### Pure text completion models\n\n.pre[These models specialize in text completion .grey-text[*tasks such as question answering, machine translation and summarization.*]]\n???\n- LLMs do no think: they *just* complete text\n--\n\n#### Instruction-following models (aka chat models)\n\n<span class=\"pre\">&lt;|im_start|>system\nYou are a professional translator&lt;|im_end|>\n&lt;|im_start|>user\nHow do I translate \"hello\" in French?&lt;|im_end|&gt;\n<span class=\"grey-text\">&lt;|im_start|>assistant\nBonjour&lt;|im_end|></span>\n</span>\n\n???\n- Chat models are tuned to follow instructions, with the addition of special tokens\n\n---\n\n# Tokens\n\nLLMs don't work with words, but with tokens.\n\n.col-6.float-left.top.no-margin[\n  .w-90.responsive.top[![](./images/tokens2.png)]\n]\n.col-6.float-left.top.no-margin[\n  .w-90.responsive.top[![](./images/tokens.png)]\n]\n\n???\n- https://platform.openai.com/tokenizer\n\n---\n\n# Limits\n\n#### .circled[Context window]\n- Common limits: .em-text[**2-4K tokens**] (GPT-4: 8k or 32K)\n- Context window limits .em-text[**input + output**]\n\n<script>\nrough('.circled', { type: 'circle', color: '#f22', strokeWidth: 4, padding: 50, animationDuration: 2000 }, 1000);\n<\/script>\n???\n- context training: O(n^2) complexity\n- 4K tokens ~ 3K words ~ 6 pages\n- 100K context windows => using tricks, with great loss of accuracy (attention)\n--\n\n#### Bias\n- LLMs may reflect the biases of the training data\n???\n- Humans do both logical and stereotypical reasoning, LLMs do not have logic\n--\n\n- Examples:\n  * Optimized code?\n  * Accessible code?\n  * Best language to learn?\n\n???\n- Who can give some code-related biases?\n\n---\n\nclass: center\n# Embeddings\n\n.w-80.responsive[\n  <object data=\"images/embedding.svg\"></object>\n]\n\n???\n- Embedding: vector representation of a piece of data, that captures the underlying structure and relationships between pieces of data\n- Embeddings are used to build vector DBs\n- This is how we \"memorize\" things (ie your data) in LLMs\n\n---\n\n# Prompt engineering\n\n#### Zero-shot\n\nGenerate output with no specific training or examples\n\n.small[*Prompt:*]\n.up[\n```\nTranslate the following text in French: \"Hello, world!\"\n```\n]\n\n.small[*Output:*]\n.up[\n```\n\"Bonjour, le monde !\"\n```\n]\n\n---\n\n# Prompt engineering\n\n#### Few-shot\n\nUse in-context examples to condition the output\n\n.small[*Prompt:*]\n.up[\n```\nBonjour Devoxx: french\nBrian is in the kitchen: english\nDanke schön: german\nDen här koden är hemsk:\n```\n]\n\n.small[*Output:*]\n.up[\n```\nswedish\n```\n]\n\n---\n\n# Prompt engineering\n\n#### Chain of thought\n\nSimulate human-like reasoning and decision-making\n\n.small[*Prompt:*\n.up[\n```\nWhen I was 6 years old, my sister was twice my age. Now I'm 30. How old is my sister?\nLet's think step by step.\n```\n]\n\n*Output:*\n.up[\n```\nSure, let's break it down step by step.\n\n1. When you were 6 years old, your sister was twice your age. This means your sister was 6 * 2 = 12 years old at that time.\n2. The age difference between you and your sister is 12 - 6 = 6 years.\n3. Now, you are 30 years old. To find out how old your sister is now, you need to add the age difference to your current age. So, 30 + 6 = 36.\n\nTherefore, your sister is currently 36 years old.\n```\n]\n]\n\n---\n\n# Prompt engineering\n\n#### Chain of thought\n\nSimulate human-like reasoning and decision-making\n\n.small[*Prompt:*\n.up[\n```\nWhen I was 6 years old, my sister was twice my age. Now I'm 30. How old is my sister?\n*Let's think step by step.\n```\n]\n\n*Output:*\n.up[\n```\nSure, let's break it down step by step.\n\n1. When you were 6 years old, your sister was twice your age. This means your sister was 6 * 2 = 12 years old at that time.\n2. The age difference between you and your sister is 12 - 6 = 6 years.\n3. Now, you are 30 years old. To find out how old your sister is now, you need to add the age difference to your current age. So, 30 + 6 = 36.\n\nTherefore, your sister is currently 36 years old.\n```\n]\n]\n\n???\n- Without \"Let's think step by step.\" => 24\n- Allow to break down a problem into smaller, simpler steps\n\n---\n\n# Prompt engineering\n\n#### Retrieval Augmented Generation\n\nUse a vector DB to retrieve relevant information and add it to augment the context\n\n.center[\n.w-75.responsive[\n<object data=\"images/rag.svg\"></object>\n]\n]\n\n---\n\n# Agents\n\nA program that perceives its environment, make decisions and takes actions to achieve goals autonomously.\n\n.center[\n.w-65.responsive[\n  <object data=\"images/agent.svg\"></object>\n]\n]\n\n---\n\n# Agents\n\n.col-3.float-left.top[\n#### Examples\n- [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT)\n- [babyAGI](https://github.com/yoheinakajima/babyagi)\n- [GPT Engineer](https://github.com/AntonOsika/gpt-engineer)\n\n#### Frameworks\n- 🦜️🔗 [LangChain](https://www.langchain.com/)\n- [Semantic Kernel](https://github.com/microsoft/semantic-kernel)\n]\n.col-9.float-left.top.no-margin[\n  .responsive.rounded[![](./images/gptengineer-demo.gif)]\n]\n\n---\n\nclass: center, middle, cover, hide-handle\nbackground-image: url(./images/copilot.jpg)\n\n???\n- Sorti en 2021\n- Initialement basé sur OpenAI Codex (derivé de GPT-3)\n- Optimisé pour le code\n\n\n---\n\nclass: big-text, clist, center, middle\n# What Copilot *doesn't do*\n\n- .baseline[It **doesn't** .em-text[send all your code] to the cloud]\n- .baseline[It **doesn't** .em-text[use your data] to train the model]\n- .baseline[It **doesn't** .em-text[understand] your app design]\n???\n- Privacy first: pas de code envoyé au cloud, pas de données utilisateurs\n\n---\n\nclass: center, middle\n# The lifecycle of a Copilot suggestion\n\n.center[\n.w-100.responsive[![](./images/completion.png)]\n]\n\n---\n\nclass: big-text, center, clist\n# Context is everything\n\n#### .large[**What's in the 🪄 Magic Sauce 🪄?**]\n- Content from open tabs\n- Code from before and after the cursor\n- Code extracts from the same file\n- Clipboard content\n\n???\n- A prompt is usually ~2-4K tokens, so it can't contain all the code\n- Copilot cherry-picks the most relevant parts of the code to build the prompt\n- Depending on the context, the prompt can be very different\n- (Soon) Code from other files in the workspace\n\n---\n\nclass: contain, hide-handle, dark\nbackground-image: url(./images/demo.png)\n\n???\n  * Demo de comment améliorer ses résultats\n    * Demo \"avancée\": code à l'envers, prompt engineering, zero-shot, few-shot, one-shot\n  * Pourquoi ca ne propose rien?\n    - Les 150 charactères de limite\n    - Code match (ex: Python)\n---\n\nclass: big-text\n# Recap\n#### .large[How to improve your suggestions]\n1. .baseline[.em-text[**Context:**]<br>Tabs, clipboard, before/after cursor, same file]\n2. .baseline[.em-text[**Prompt engineering:**]<br>Give examples, think step by step]\n3. .baseline[.em-text[**Approach:**]<br> Code in reverse, split complex problems in smaller parts]\n\n---\n\nclass: center, middle, impact\n# AI-enhanced development:\n# .baseline[.large[It's a new .ib.animated.bounce.alt-text[skill]]]\n\n---\n\nclass: center, middle\n# .large[Legal concerns ⚖️]\n.small[https://blogs.microsoft.com/on-the-issues/2023/09/07/copilot-copyright-commitment-ai-legal-concerns/]\n\n---\n\nclass: center\n# Productivity increase\n.center[\n  .w-55.responsive[![](./images/copilot-stats.png)]\n]\n\n---\n\nclass: center, middle, big-text\nAI is no magic 🤷<br>\n--\n\n.baseline.large[but it's still a .em-text[game changer]]\n\n???\n- L'IA n'est pas magique et ne remplace pas un dev\n- ...mais peut grandement aider a la productivité\n- Ca va changer notre métier, avec des bons et des mauvais côtés\n  * par ex les tests de code :D\n\n---\n\nclass: cover, full\nbackground-image: url(./images/highfive-hq.jpg)\n\n???\nDon't be afraid of it!\n\n---\n\nclass: middle, center, hide-handle, clist, big-text\n\n# Thank you!\n\n.arrow[\n  .w-45.responsive[![](images/arrow.svg)]\n]\n\n.row.table.middle[\n.col-6.right.space-right[\n<object data=\"images/qrcode.svg\"></object>\n]\n.col-6.left[\n.large[[bit.ly/ai-for-dev](https://bit.ly/ai-for-dev)]\n]\n]\n\n@sinedied | @cmaneu\n\n<style>\n.arrow {\n  position: absolute;\n  top: 24%;\n  left: 40%;  \n}\n</style>\n\n---\n\n# References & going further\n\n.full-layer.with-margins.right.space-right.noclick[\n<br>\n.w-25.responsive.circle[![](images/diver.jpg)]\n]\n\n- [GitHub Copilot Video series](https://www.youtube.com/playlist?list=PLj6YeMhvp2S5_hvBl2SE-7YCHYlLQ0bPt)\n- [How GPT models work](https://towardsdatascience.com/how-gpt-models-work-b5f4517d5b5)\n- [Practical Deep Learning](https://course.fast.ai/)\n- [OpenAI tokenizer](https://platform.openai.com/tokenizer)\n- [Prompt Engineering Guide](https://www.promptingguide.ai)\n- [GitHub Blog on Copilot](https://github.blog/?s=copilot)\n- [Awesome LangChain](https://github.com/kyrolabs/awesome-langchain)\n- [Responsible Generative AI training](https://learn.microsoft.com/training/modules/responsible-generative-ai/)\n- [How to write better prompts for GitHub Copilot](https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/)\n- [Microsoft announces new Copilot Copyright Commitment for customers](https://blogs.microsoft.com/on-the-issues/2023/09/07/copilot-copyright-commitment-ai-legal-concerns/)\n- [ChatGPT + Enterprise data with Azure OpenAI and Cognitive Search](https://github.com/Azure-Samples/azure-search-openai-javascript/)\n- [About Samsung ChatGPT data leak](https://techcrunch.com/2023/05/02/samsung-bans-use-of-generative-ai-tools-like-chatgpt-after-april-internal-data-leak/)\n\n---\n\nexclude: true\nclass: middle, center, hide-handle, clist\n\n.w-90.responsive[\n<object data=\"images/thanks.svg\"></object>\n]\n\n???\nFeedback please!",
        ratio: '16:9',
        highlightLines: true,
        countIncrementalSlides: false,
        highlightStyle: 'github'
      });
      return slideshow;
    }
  </script>
</head>
<script src="code.js"></script>
<body onload="window.slideshow = create(); window.setup()">
</body>
</html>